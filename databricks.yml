bundle:
  name: turbine_pipeline

targets:
  dev:
    mode: development
    default: true
    workspace:
      host: https://adb-{}.azuredatabricks.net

resources:
  jobs:
    turbine-pipeline:
      name: turbine-pipeline
      tasks:
        - task_key: run-turbine-pipeline
          spark_python_task:
            python_file: src/main.py
            parameters: ["dbfs:/FileStore/ashok/*.csv"]
          existing_cluster_id: xxxx-xxxx-dv2esr0a
      schedule:
        quartz_cron_expression: "0 0 * * * ?"
        timezone_id: UTC

  # Optionally, there could be 'staging' or 'prod' targets here.
  # prod:
  #   workspace:
  #     host: https://adb-{}.azuredatabricks.net
